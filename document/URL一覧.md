# URL一覧
- [フィードフォワードネットワークについて](https://yhayato1320.hatenablog.com/entry/2021/01/25/152827)
- [HuggingFace Transformers 4.5 : 利用方法 : 訓練と再調整](https://torch.classcat.com/2021/05/11/huggingface-transformers-4-5-training/)
- [BERT2BERTによるニュース記事のタイトル生成](https://qiita.com/m__k/items/30cea9efba495b13fbd2)
- [【Python】Word2Vecの使い方](https://qiita.com/kenta1984/items/93b64768494f971edf86)
- [Alpaca-LoRAでの学習](https://note.com/masa_kazama/n/nabaa6dfec741)
- [Transformerの学習済みモデルをLambdaにデプロイする(SAM)](https://nagomi-informal.net/archives/709)
- [【2022】ディープラーニングとは？](https://jp.morgenrot.cloud/blog/kinds-of-deep-learning/)
- [OpenAIのAPI料金の計算方法](https://zenn.dev/umi_mori/books/chatbot-chatgpt/viewer/how_to_calculate_openai_api_prices)
- [【Huggingface Transformers】日本語↔英語の翻訳を実装する](https://tt-tsukumochi.com/archives/7540)
- [PyTorch を使って Transformer による翻訳モデルを実践する](https://www.dskomei.com/entry/2021/05/24/165158)
- [word2vecの学習済み日本語モデルを公開します](https://aial.shiroyagi.co.jp/2017/02/japanese-word2vec-model-builder/)
- [Hugging FaceのLearning Rateを調整するためのSchedulerについて深堀する](https://dev.classmethod.jp/articles/huggingface-usage-scheluder-type/)
- []()
- []()
- []()