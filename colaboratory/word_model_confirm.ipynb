{"cells":[{"cell_type":"markdown","source":["# 学習後モデルの性能を調査"],"metadata":{"id":"zDUd4HOUVqrC"}},{"cell_type":"markdown","source":["## Google Driveとの連携"],"metadata":{"id":"WQNa6Hk8_BE1"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"CJc64wXG-8hZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ln -s \"/content/drive/My Drive/ColabNotebooks\" \"/content/ColabNotebooks\""],"metadata":{"id":"IkEd_M93A8A0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 必要パッケージのインストール"],"metadata":{"id":"x57jwoxnVvDd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LEzEE5lWdnuJ"},"outputs":[],"source":["!pip install -r /content/ColabNotebooks/requirements.txt"]},{"cell_type":"markdown","source":["## 翻訳 & 評価"],"metadata":{"id":"r9NN07gmV19u"}},{"cell_type":"markdown","source":["### パッケージのimport"],"metadata":{"id":"2MCNArwhBZJE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_nRxsP_eZY3"},"outputs":[],"source":["import gensim\n","import pandas as pd\n","from gensim.models.word2vec import Word2Vec\n","from transformers import (\n","    T5Tokenizer,\n","    T5ForConditionalGeneration,\n",")\n","%matplotlib inline\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["### モデルのロード"],"metadata":{"id":"Q4UcwY7hOVej"}},{"cell_type":"code","source":["model_path = \"/content/ColabNotebooks/model/\"\n","# model_path = \"t5-small\""],"metadata":{"id":"p96tCu43flvz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# トークナイザとモデルの準備\n","tokenizer = T5Tokenizer.from_pretrained(model_path)\n","model = T5ForConditionalGeneration.from_pretrained(model_path)\n","\n","# 評価モード\n","model.eval()"],"metadata":{"id":"hzXFIwI_BjYd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 検証用モデルの用意\n","word_model = Word2Vec.load(\"/content/ColabNotebooks/model_word2vec/word2vec.gensim.model\")"],"metadata":{"id":"xfsvv4HgOsbd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 固定値の決定"],"metadata":{"id":"Hk7EaznwYKIn"}},{"cell_type":"code","source":["# 生成元のシーケンスの最大長を定義します。\n","max_length_src = 32\n","\n","# 生成されるシーケンスの最大長を定義します。\n","# これは問題の性質によって異なりますが、\n","# 一般的にはソーステキストの長さの2倍程度を指定することが推奨されます。\n","max_length_target = 64\n","\n","# 同じ文の繰り返し（モード崩壊）へのペナルティを定義します。\n","# 値が大きいほど、生成されるテキストの繰り返しを避けることができます。\n","# 適切な値は実験によりますが、通常は1.0以上の値を設定します。\n","repetition_penalty = 8.0\n","\n","# 生成にランダム性を入れる温度パラメータです。\n","# 値が小さいほど出力は決定的になり、大きいほど出力はランダムになります。\n","# 適切な値は問題に依存しますが、一般的には0.7から1.0の間で設定します。\n","temperature=1.0\n","\n","# ビームサーチの探索幅を定義します。\n","# ビームサーチは、生成される各ステップで最良の候補を保持し、\n","# それらの候補から次のステップを生成します。\n","# num_beamsが大きいほど、より多くの候補が考慮され、\n","# 生成されるテキストの質が向上する可能性がありますが、\n","# 計算コストも増加します。一般的には2から10の間で設定します。\n","num_beams=4\n","\n","# 生成結果の多様性を生み出すためのペナルティパラメータです。\n","# これは特定のトークンが選択されることに対するペナルティを増加させ、\n","# 結果として生成されるテキストの多様性を高めます。適切な値は問題と目的に依存します。\n","diversity_penalty=1.0\n","\n","# ビームサーチのグループ数を定義します。\n","# これは、ビームを複数のグループに分割し、\n","# それぞれのグループで独立にサーチを行うことを可能にします。\n","# これにより、出力の多様性が増加します。\n","num_beam_groups=4\n","\n","\n","# 生成する文の数を定義します。\n","# このパラメータは、複数の異なる出力を生成したい場合に使用します。\n","# この値はnum_beams以上である必要があります。\n","num_return_sequences=1\n","\n","prefix = \"translate English to Japanese: \"\n","# prefix = \"translate English to French: \""],"metadata":{"id":"7O-iNuRnYEs5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 生成メソッドの作成"],"metadata":{"id":"4j0Erx8bLwxA"}},{"cell_type":"code","source":["def generate(\n","    model: T5ForConditionalGeneration, tokenizer: T5Tokenizer, input: str\n",") -> str:\n","    \"\"\"与えられた入力に対応した、モデルの出力を返します。\n","\n","    引数:\n","        model (T5ForConditionalGeneration): 翻訳に使用するモデル\n","\n","        tokenizer (T5Tokenizer): テキストをトークン化するためのトークナイザ\n","\n","        input (str): 入力\n","\n","    戻り値:\n","        str: 翻訳された日本語の単語\n","    \"\"\"\n","    batch = tokenizer(\n","        f\"{prefix}{input}\",\n","        max_length=max_length_src,\n","        truncation=True,\n","        padding=\"max_length\",\n","        return_tensors=\"pt\",\n","    )\n","\n","    # 生成処理を行う\n","    outputs = model.generate(\n","        input_ids=batch[\"input_ids\"],\n","        attention_mask=batch[\"attention_mask\"],\n","        early_stopping=True,\n","        max_length=max_length_target,\n","        repetition_penalty=repetition_penalty,\n","        temperature=temperature,\n","        num_beams=num_beams,\n","        diversity_penalty=diversity_penalty,\n","        num_beam_groups=num_beam_groups,\n","        num_return_sequences=num_return_sequences,\n","    )\n","\n","    generated_texts = [\n","        tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs\n","    ]\n","    return generated_texts[0]"],"metadata":{"id":"zFjR0JJ9LwV7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 翻訳の実行"],"metadata":{"id":"Wbrz-H9KYWFt"}},{"cell_type":"code","source":["input = \"Color\"\n","generated_translation = generate(model, tokenizer, input)\n","print(f\"入力: {input} / 出力: {generated_translation}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fL-2_I2tYTxs","executionInfo":{"status":"ok","timestamp":1685632648823,"user_tz":-540,"elapsed":379,"user":{"displayName":"dahutos","userId":"09521740508232458051"}},"outputId":"836bf5ad-9104-45a8-c8aa-a9a830321c37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["入力: Color / 出力: Japanische Farbe\n"]}]},{"cell_type":"markdown","source":["### 評価の実行"],"metadata":{"id":"hNd8PihkOb3n"}},{"cell_type":"code","source":["similarities = []\n","\n","# データフレームの取得\n","df = pd.read_csv('/content/ColabNotebooks/input/en_and_ja_10.csv')\n","\n","for index, row in df.iterrows():\n","    english_word = row[\"English\"]\n","    correct_translation = row[\"Japanese\"]\n","    generated_translation = generate(model, tokenizer, english_word)\n","    is_not_found = False\n","    try:\n","        similarity = word_model.wv.similarity(\n","            correct_translation, generated_translation\n","        )\n","    except KeyError:\n","        is_not_found = True\n","        print(\n","            f\"単語が見つからないです: {correct_translation} または {generated_translation} がモデルに存在しません。\"\n","        )\n","    # Word2Vecモデルの学習データに含まれていなかった場合は追加しない\n","    if not is_not_found:\n","        similarities.append(similarity)\n","\n","if len(similarities) > 0:\n","  plt.plot(similarities)\n","  plt.show()\n","  print(f\"平均類似度: {sum(similarities) / len(similarities)}\")\n","else: \n","  print(\"データが空です。\")"],"metadata":{"id":"FrPnk-zvN-Ni"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["WQNa6Hk8_BE1","x57jwoxnVvDd","2MCNArwhBZJE","Q4UcwY7hOVej","4j0Erx8bLwxA","Wbrz-H9KYWFt","hNd8PihkOb3n"],"mount_file_id":"1I-CGm9eq8Fs5gkNsNfop3FY7VObNFiWR","authorship_tag":"ABX9TyMAG5fojl9bImuVDzlkGoG/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}